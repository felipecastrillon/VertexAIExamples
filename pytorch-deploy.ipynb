{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f49acfbc-ddbb-4469-b280-17ba6e636a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mERROR:\u001b[0m (gcloud.components.update) unrecognized arguments: -y \n",
      "\n",
      "To search the help text of gcloud commands, run:\n",
      "  gcloud help -- SEARCH_TERMS\n"
     ]
    }
   ],
   "source": [
    "!gcloud components update -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8a46faaa-552a-422a-b2e8-379bddbbb913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "felipe-sandbox\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "PROJECT_ID = \"felipe-sandbox\"\n",
    "os.environ[\"PROJECT_ID\"] = PROJECT_ID\n",
    "print(os.environ[\"PROJECT_ID\"])\n",
    "APP_NAME = \"pytorch-mnist-example\"\n",
    "os.environ[\"APP_NAME\"] = APP_NAME\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebbf178a-00d7-48fc-8092-c1278e301b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'serve'...\n",
      "Note: checking out 'ccff97780628a01ab3b47d835d8e9dd01377d881'.\n",
      "\n",
      "You are in 'detached HEAD' state. You can look around, make experimental\n",
      "changes and commit them, and you can discard any commits you make in this\n",
      "state without impacting any branches by performing another checkout.\n",
      "\n",
      "If you want to create a new branch to retain commits you create, you may\n",
      "do so (now or later) by using -b with the checkout command again. Example:\n",
      "\n",
      "  git checkout -b <new-branch-name>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "git clone https://github.com/pytorch/serve.git \\\n",
    "  --branch=v0.3.0 \\\n",
    "  --depth=1\n",
    "\n",
    "cd serve/examples/image_classifier/mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "022b5818-63fd-4a15-9df2-fd0b04cff125",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Create request issued for: [pytorch-mnist-example]\n",
      "Waiting for operation [projects/felipe-sandbox/locations/us-central1/operations/533c7b01-9c22-4974-a5f9-30d98cdde737] to complete...\n",
      "......done.\n",
      "Created repository [pytorch-mnist-example].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud artifacts repositories create pytorch-mnist-example \\\n",
    " --repository-format=docker \\\n",
    " --location=us-central1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc5d8e60-4064-4dbf-8f58-15e1bbd9655c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat > Dockerfile <<END\n",
    "FROM pytorch/torchserve:0.3.0-cpu\n",
    "\n",
    "COPY mnist.py mnist_cnn.pt mnist_handler.py /home/model-server/\n",
    "\n",
    "USER root\n",
    "RUN printf \"\\nservice_envelope=json\" >> /home/model-server/config.properties\n",
    "RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home/model-server/config.properties\n",
    "RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /home/model-server/config.properties\n",
    "USER model-server\n",
    "USER model-server\n",
    "\n",
    "\n",
    "# expose health and prediction listener ports from the image\n",
    "EXPOSE 7080\n",
    "EXPOSE 7081\n",
    "\n",
    "RUN torch-model-archiver \\\n",
    "  --model-name=mnist \\\n",
    "  --version=1.0 \\\n",
    "  --model-file=/home/model-server/mnist.py \\\n",
    "  --serialized-file=/home/model-server/mnist_cnn.pt \\\n",
    "  --handler=/home/model-server/mnist_handler.py \\\n",
    "  --export-path=/home/model-server/model-store\n",
    "\n",
    "CMD [\"torchserve\", \\\n",
    "     \"--start\", \\\n",
    "     \"--ts-config=/home/model-server/config.properties\", \\\n",
    "     \"--models\", \\\n",
    "     \"mnist=mnist.mar\"]\n",
    "END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ed9e4b02-1489-48d9-b469-cce57ab380b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  56.66MB\n",
      "Step 1/12 : FROM pytorch/torchserve:0.3.0-cpu\n",
      " ---> d7dbb9636522\n",
      "Step 2/12 : COPY mnist.py mnist_cnn.pt mnist_handler.py /home/model-server/\n",
      " ---> Using cache\n",
      " ---> 51a673abd201\n",
      "Step 3/12 : USER root\n",
      " ---> Using cache\n",
      " ---> 64289076516c\n",
      "Step 4/12 : RUN printf \"\\nservice_envelope=json\" >> /home/model-server/config.properties\n",
      " ---> Using cache\n",
      " ---> b438f3292c50\n",
      "Step 5/12 : RUN printf \"\\ninference_address=http://0.0.0.0:7080\" >> /home/model-server/config.properties\n",
      " ---> Using cache\n",
      " ---> e029e58a67de\n",
      "Step 6/12 : RUN printf \"\\nmanagement_address=http://0.0.0.0:7081\" >> /home/model-server/config.properties\n",
      " ---> Using cache\n",
      " ---> 6a799e02f151\n",
      "Step 7/12 : USER model-server\n",
      " ---> Using cache\n",
      " ---> f958f7a15e8c\n",
      "Step 8/12 : USER model-server\n",
      " ---> Using cache\n",
      " ---> f80e468887f9\n",
      "Step 9/12 : EXPOSE 7080\n",
      " ---> Using cache\n",
      " ---> 97bb2a323001\n",
      "Step 10/12 : EXPOSE 7081\n",
      " ---> Using cache\n",
      " ---> 391ceab33826\n",
      "Step 11/12 : RUN torch-model-archiver   --model-name=mnist   --version=1.0   --model-file=/home/model-server/mnist.py   --serialized-file=/home/model-server/mnist_cnn.pt   --handler=/home/model-server/mnist_handler.py   --export-path=/home/model-server/model-store\n",
      " ---> Using cache\n",
      " ---> 8b17a30eac96\n",
      "Step 12/12 : CMD [\"torchserve\",      \"--start\",      \"--ts-config=/home/model-server/config.properties\",      \"--models\",      \"mnist=mnist.mar\"]\n",
      " ---> Using cache\n",
      " ---> e54039662866\n",
      "Successfully built e54039662866\n",
      "Successfully tagged us-central1-docker.pkg.dev/felipe-sandbox/pytorch-mnist-example/serve-mnist:latest\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "docker build \\\n",
    "  --tag=us-central1-docker.pkg.dev/$PROJECT_ID/$APP_NAME/serve-mnist \\\n",
    "  ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7dd385b7-70bb-43ff-b3a4-42578892e696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ed4a0b44ae21d3867f0a4a693166b795c2ec6ac5d4d399cb7c130935a8139ffd\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "docker run -d -p 7080:7080 --name=local_mnist2 \\\n",
    "  us-central1-docker.pkg.dev/$PROJECT_ID/$APP_NAME/serve-mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dd30429e-c35d-4ab5-a3e0-f2aff90a9257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status\": \"Healthy\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!curl localhost:7080/ping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b28c9905-5dfb-495b-bea2-a9ef285304d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"predictions\": [3]}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   422  100    20  100   402    588  11823 --:--:-- --:--:-- --:--:-- 12411\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat > instances.json <<END\n",
    "{\n",
    "  \"instances\": [\n",
    "    {\n",
    "      \"data\": {\n",
    "        \"b64\": \"$(base64 --wrap=0 test_data/3.png)\"\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "END\n",
    "\n",
    "curl -X POST \\\n",
    "  -H \"Content-Type: application/json; charset=utf-8\" \\\n",
    "  -d @instances.json \\\n",
    "  localhost:7080/predictions/mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5098ad68-a60d-4a73-9af3-ae4fd0f5a8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_mnist2\n"
     ]
    }
   ],
   "source": [
    "!docker stop local_mnist2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "68225403-960f-4b8a-b979-e9114db8d58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default tag: latest\n",
      "The push refers to repository [us-central1-docker.pkg.dev/felipe-sandbox/pytorch-mnist-example/serve-mnist]\n",
      "175e0b2fdf31: Preparing\n",
      "0dee4818e1b0: Preparing\n",
      "ffa1fd9a60c2: Preparing\n",
      "99baa2214840: Preparing\n",
      "eaaf0853d3af: Preparing\n",
      "5f70bf18a086: Preparing\n",
      "4f22e947a5a8: Preparing\n",
      "e681618568c0: Preparing\n",
      "711c3c5d494b: Preparing\n",
      "ac4e7c2ae042: Preparing\n",
      "44486128a8c5: Preparing\n",
      "c761bb163c21: Preparing\n",
      "d54e4a309a82: Preparing\n",
      "fe6d8881187d: Preparing\n",
      "23135df75b44: Preparing\n",
      "b43408d5f11b: Preparing\n",
      "c761bb163c21: Waiting\n",
      "d54e4a309a82: Waiting\n",
      "fe6d8881187d: Waiting\n",
      "23135df75b44: Waiting\n",
      "711c3c5d494b: Waiting\n",
      "b43408d5f11b: Waiting\n",
      "ac4e7c2ae042: Waiting\n",
      "44486128a8c5: Waiting\n",
      "4f22e947a5a8: Waiting\n",
      "5f70bf18a086: Waiting\n",
      "e681618568c0: Waiting\n",
      "175e0b2fdf31: Layer already exists\n",
      "0dee4818e1b0: Layer already exists\n",
      "99baa2214840: Layer already exists\n",
      "ffa1fd9a60c2: Layer already exists\n",
      "eaaf0853d3af: Layer already exists\n",
      "4f22e947a5a8: Layer already exists\n",
      "5f70bf18a086: Layer already exists\n",
      "e681618568c0: Layer already exists\n",
      "711c3c5d494b: Layer already exists\n",
      "ac4e7c2ae042: Layer already exists\n",
      "44486128a8c5: Layer already exists\n",
      "c761bb163c21: Layer already exists\n",
      "d54e4a309a82: Layer already exists\n",
      "23135df75b44: Layer already exists\n",
      "fe6d8881187d: Layer already exists\n",
      "b43408d5f11b: Layer already exists\n",
      "latest: digest: sha256:de113939aff6a1f951248db9e5ad45f0925850a2a6adec2636893d9ebdfab623 size: 3660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Your config file at [/home/jupyter/.docker/config.json] contains these credential helper entries:\n",
      "\n",
      "{\n",
      "  \"credHelpers\": {\n",
      "    \"gcr.io\": \"gcloud\",\n",
      "    \"us.gcr.io\": \"gcloud\",\n",
      "    \"eu.gcr.io\": \"gcloud\",\n",
      "    \"asia.gcr.io\": \"gcloud\",\n",
      "    \"staging-k8s.gcr.io\": \"gcloud\",\n",
      "    \"marketplace.gcr.io\": \"gcloud\",\n",
      "    \"us-central1-docker.pkg.dev\": \"gcloud\"\n",
      "  }\n",
      "}\n",
      "Adding credentials for: us-central1-docker.pkg.dev\n",
      "gcloud credential helpers already registered correctly.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud auth configure-docker us-central1-docker.pkg.dev\n",
    "docker push us-central1-docker.pkg.dev/$PROJECT_ID/$APP_NAME/serve-mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bfad7a2a-c84d-4253-b80c-0dc124165f20",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aiplatform' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2570/3462156169.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maiplatform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPROJECT_ID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstaging_bucket\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBUCKET_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'aiplatform' is not defined"
     ]
    }
   ],
   "source": [
    "aiplatform.init(project=PROJECT_ID, staging_bucket=BUCKET_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de62a5fd-4c9e-473f-89f3-35d1038d959f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m80",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m80"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
